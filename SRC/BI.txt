P1
##########################################################################################################################################
create database and tables 
##########################################################################################################################################
P2
Warehouse
##########################################################################################################################################
P3
Cube
Create table 
Run query:
SELECT COUNT(DISTINCT) col1),col2,col3
FROM Table
GROUP BY
CUBE(col2,col3)
##########################################################################################################################################
P4
star schema
1 fact table
4 dimension tables 
construct tables 
add data
create database diagram

##########################################################################################################################################
P5
snowflake

##########################################################################################################################################
P6
SQL Sever-> New query->
-- Creating Sales Table

DROP TABLE IF EXISTS sales;
CREATE TABLE sales (
    brand VARCHAR NOT NULL,
    segment VARCHAR NOT NULL,
    quantity INT NOT NULL,
    PRIMARY KEY (brand, segment)
);


-- Inserting values into Sales Table

INSERT INTO sales (brand, segment, quantity)
VALUES
    ('ABC', 'Premium', 100),
    ('ABC', 'Basic', 200),
    ('XYZ', 'Premium', 100),
    ('XYZ', 'Basic', 300);


-- Viewing all data

select * from sales;


-- Roll up

SELECT
    brand,
    segment,
    SUM (quantity)
FROM
    sales
GROUP BY
    ROLLUP (brand, segment)
ORDER BY
    brand,
    segment;


-- slice

SELECT
    *
FROM
    sales
WHERE
	segment = 'Basic';


-- Dice

SELECT
    *
FROM
    sales
WHERE
	segment = 'Basic' AND quantity > 250;
-- Drill Down
Drilll downSELECT
    
    emp_gender,
    SUM (emp_pno)
FROM
    emp1
GROUP BY
 
    
    (emp_gender)
    having SUM (emp_pno)>2

P7
##########################################################################################################################################
-- 1) SQL Query to illustrate the basic functionality of CUBE.
SELECT COUNT(DISTINCT employeeid), departmentid, city
FROM Employee1
GROUP BY
CUBE(departmentid,city);
-- In the above example, we have tried to find the count of employees along with each department and city.


/* 2) Find the number of distinct employees in each department 
grouped by their salaries earning a salary between 12000 and 13000./
SELECT COUNT(DISTINCT employeeid), departmentid, salary
FROM Employee1
WHERE salary BETWEEN '12000' AND '13000'
GROUP BY
CUBE(departmentid,salary);
-- The above example illustrates the use of the WHERE clause in the CUBE query.



-- 3) Summarize the salaries of employees along with each department and city and salary.
SELECT sum(salary),departmentid, city
FROM employee1
GROUP BY
CUBE(departmentid,city,salary);



-- 4) Summarize the salaries of employees from Mumbai and Thane along with each 
-- department(with department name in the resulting set) ordered by salaries and 
-- departmentname.
SELECT sum(e.salary),d.departmentname, city
FROM employees as e INNER JOIN department as d
ON e.departmentid = d.departmentid
WHERE e.city = 'Mumbai' OR e.city = 'Thane'
GROUP BY
CUBE(d.departmentname,e.city)
HAVING SUM(e.salary) < '60000'
ORDER BY sum(e.salary)DESC ,d.departmentname ASC;



-- Conclusion
/SQL CUBE is metadata which is used to group data along more than one column. 
This is very helpful in summarizing data along with multiple axes. 
Hence, helps to fasten up analysis and reporting.*/
P8
##########################################################################################################################################
Data Cleaning
Preferable use excel 
remove null vals either by replacing by default values or eliminating rows
replace null by defaults
select col -> goto specials select balnks -> =cell value ($a$3)-> ctrl+enter
--------------------------------
using pandas
import pandas as pd
import numpy as np



movie_data.info()

movie_data.isna().sum()

def drop_null(dataset,col_name):
    movie_data = dataset.dropna(subset=[col_name])
    return movie_data
movie_data = drop_null(movie_data,'RunTime')
movie_data.info()

movie_data = drop_null(movie_data,'GENRE')
movie_data.info()

movie_data = drop_null(movie_data,'YEAR')
movie_data.info()

def fill_null():
    data = {'Gross':'$0.0M','RATING':0.0,'VOTES':'0'}
    for col,val in data.items():
        print(col)
        movie_data[col] = movie_data[col].fillna(val)
    return movie_data
data_to_clean = fill_null()
data_to_clean.info()
data_to_clean.head()

def cleaner(col):
    cleaned_col = data_to_clean.loc[:,[col]].apply(lambda e:[data[1:].rstrip() for data in e])
    return cleaned_col
data_to_clean['GENRE']=cleaner('GENRE')

data_to_clean['ONE-LINE'] = cleaner("ONE-LINE")
data_to_clean['STARS']=cleaner("STARS")
data_to_clean.head()

data_to_clean['Gross'] = data_to_clean.loc[:,['Gross']].apply(lambda e: [float(data[1:-1]) for data in e]) 
data_to_clean.head()

data_to_clean['YEAR'] = data_to_clean.loc[:,['YEAR']].apply(lambda e: [data[1:-1] for data in e])
data_to_clean.head()

'''def deep_year():
    for dataY in data_to_clean['YEAR']:
        if dataY[-1] == '-':
            data_to_clean['YEAR'] = dataY[:-1]
        else: 
            data_to_clean['YEAR'] = dataY
    return data_to_clean
data_to_clean = deep_year()
data_to_clean.head()'''

data_to_clean['Year'] = data_to_clean['YEAR'].str.extract(r'([0-9]{4}–.*|[0-9]{4})')
data_to_clean['Year'] = data_to_clean['Year'].str.strip().replace(")","")

def extract_year(year):
    if year[-3:] == '– )':
        return year.replace('– )',"–")
    else:
        return year.replace(')',"")

data_to_clean['Year'] = data_to_clean['Year'].fillna('Unknown')
data_to_clean['Year'] = data_to_clean['Year'].apply(lambda y: extract_year(y))
    
year_count = data_to_clean[data_to_clean['Year'] != 'Unknown']['Year'].value_counts().reset_index().rename(columns = {'Year':'Count','index':'Year'})
year_count.head()

data_to_clean.head()

data_to_clean.to_csv('Cleaned.csv')
##########################################################################################################################################
P9
dashboard